<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		    <h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
    <div style="text-align: center;">Names: Mark MacDermott, Seongsoo Park</div>
    <br>
    <div style="text-align: center;">
        Link to webpage: <a href="https://ranototaudio.github.io/184-hw/">HW Writeups</a><br>
        Link to GitHub repository: <a href="https://github.com/RanototAudio">ranototaudio</a>
    </div>

    <figure>
        <img src="def.jpg" alt="rano" style="width:50%"/>
    </figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h3>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>

		<p> 
		As part of tasks 1.1 and 1.2 I implemented a process for generating rays which are sent from the camera through points located within a single pixel.
		The first function I implemented was generate_ray(double x, double y) which takes in a normalized (x,y) ∈ [0,1] x [0,1] coordinate and outputs a ray in world space.
		Some brief definitions to serve as reminders:
		</p>

		<ul>
			<li>Image Space: 2D discrete coordinate system corresponding to pixel indices on the rendered image (e.g., (x,y) in pixel units).</li>
			<li>Camera Space: 3D coordinate system with the camera at the origin, camera axes aligned with its orientation. Used for projecting world-space geometry into a view-dependent frame.</li>
			<li>World Space: 3D global coordinate system defining absolute positions and orientations of all objects and the camera. Used as the primary reference for scene construction and object placement.</li>
			<li>Screen Space – A 2D coordinate system representing positions on the camera’s projection plane (sensor or virtual film) in the camera’s local coordinate frame. It is derived by projecting 3D points onto a canonical plane (usually 1 unit away from the pinhole along the camera’s -z axis). Unlike image space, which uses normalized pixel indices, screen space uses physical or frustum-relative coordinates [−tan⁡(hFov/2),+tan⁡(hFov/2)] directly tied to the camera’s field of view.</li>
		</ul> 

		<p>
		We first transform the image coordinates to screen space which exists within camera space, generate the ray in the camera space, and finally transform it into a ray in the world space.
		So to start we calculate the bounds of screen space and then use linear interpolation to calculate our new position.
		The horizontal/vertical field of view (hFov, vFov) define how wide/tall the camera’s frustum is.
		We convert the given hFov and vFov from degrees to radians for tan calculation.
		Finally the Z-coordinate for our final point is set at -1.0 because the screen exists as a plane.
		Thus (x, y) ∈ [0,1] is remapped to physical sensor coordinates ∈ [xmin, xmax] × [ymin, ymax]:
		</p>

		<pre><code>
		// map to screen
		double hFov_rad = hFov * PI / 180.0;
		double vFov_rad = vFov * PI / 180.0;

		double xmin = -tan(0.5 * hFov_rad);
		double xmax = tan(0.5 * hFov_rad);
		double ymin = -tan(0.5 * vFov_rad);
		double ymax = tan(0.5 * vFov_rad);

		double X_cam = xmin + (xmax - xmin) * x;
		double Y_cam = ymin + (ymax - ymin) * y;
		Vector3D P_cam(X_cam, Y_cam, -1.0);
		</code></pre>

		<p>
		Now that we have our point in screen space we are able to compute the ray in camera space simply by taking the unit vector of P_cam.
		We finally map the camera space view vector to world space using the provided c2w matrix. 
		The c2w columns are the camera’s basis vectors in world space (u, v, w)
		w is the forward view direction and points to the middle of screen space.
		u is the camera's right vector perpendicular to both w and v.
		v is the up vector relative to the camera.
		</p>

		<pre><code>
		//compute view direction
		Vector3D v_cam = P_cam.unit();

		//map to worldspace
		Vector3D v_world = (P_cam.x * c2w[0]) + (P_cam.y * c2w[1]) + (P_cam.z * c2w[2]);
		</code></pre>

		<p>
		Finally we return the Ray object with correct parameters. 
		nclip and fclip are both greater than zero and represent the so-called near and far clipping planes. 
		We consider everything that lies outside these two clipping planes invisible to the camera.
		this-> = o and v_world = d.
		</p>

		<pre><code>
		//construct ray
		Ray newRay = Ray(this->pos, v_world);
		newRay.min_t = this->nClip;
		newRay.max_t = this->fClip;

		return newRay;
		</code></pre>

		<p>
		The second function I implemented was raytrace_pixel() which estimates the radiance (color) for a single pixel (x, y) by Monte Carlo path tracing.
		It does this through the following steps. First generating multiple rays through that pixel at randomized positions.
		Second tracing each ray into the scene to estimate incoming light via global illumination.
		Third averaging the contributions of all samples to get the pixel’s final color.
		</p>

		<pre><code>
		int num_samples = ns_aa;
		Vector3D sum(0.0, 0.0, 0.0);
		
		for (int i = 0; i < num_samples; i++) {
			double x_norm = (x + gridSampler->get_sample().x) / sampleBuffer.w;
			double y_norm = (y + gridSampler->get_sample().y) / sampleBuffer.h;

			sum += est_radiance_global_illumination(camera->generate_ray(x_norm, y_norm));

		}
		sum = sum / num_samples;
		sampleBuffer.update_pixel(sum, x, y);
		</code></pre>

		
		<p><strong>Rendering Equation:</strong></p>
		<p>
		\[
		L_o(p, \omega_o) = L_e(p, \omega_o) +
		\int_{\Omega} f_r(p, \omega_i, \omega_o)\, L_i(p, \omega_i)\, \cos\theta_i \, d\omega_i
		\]
		This is implemented via est_radiance_global_illumination()
		</p>

		<p><strong>Monte Carlo Estimator:</strong></p>
		<p>
		\[
		\hat{L}_o(p, \omega_o) =
		\frac{1}{N} \sum_{i=1}^N
		\frac{f_r(p, \omega_i, \omega_o)\, L_i(p, \omega_i)\, \cos\theta_i}{p(\omega_i)}
		\]
		This is implemented via summing and averaging the radiance values returned.
		</p>

		<p>
		Next I implemented Triangle::has_intersection(...) and Triangle::intersect(...)
		The ray equation is defined as follows: r(t) = o + td. r(t) is a point along the ray at timestop t.
		o is the origin or start position of the ray at timestop zero. d is a vector representing the direction that the ray travels from the origin.
		In order to solve for t, the time at which the ray intersects the triangle, we will use the Möller–Trumbore Algorithm.
		The Möller–Trumbore algorithm solves the ray-triangle intersection analytically by expressing the intersection point in terms of barycentric coordinates.
		</p>

		<p>
		Given a triangle defined by vertices \(P_0\), \(P_1\), and \(P_2\), we can express any point
		within the triangle using <strong>barycentric coordinates</strong>:
		</p>

		<p>
		\[
		P = \alpha P_0 + \beta P_1 + \gamma P_2
		\]
		</p>

		<p>
		We define:
		\[
		b_1 = \beta, \quad b_2 = \gamma, \quad \alpha = 1 - b_1 - b_2
		\]
		</p>

		<p>
		Substituting \(\alpha\):
		\[
		P = (1 - b_1 - b_2)P_0 + b_1 P_1 + b_2 P_2
		\]
		</p>

		<p>
		The ray equation is:
		\[
		r(t) = O + tD
		\]
		Substitute \(P = r(t)\):
		\[
		O + tD = (1 - b_1 - b_2)P_0 + b_1 P_1 + b_2 P_2
		\]
		</p>

		<p>
		Rearrange:
		\[
		O - P_0 = -tD + b_1 (P_1 - P_0) + b_2 (P_2 - P_0)
		\]
		</p>

		<p>
		Expressed in matrix form:
		</p>

		<p>
		\[
		\begin{bmatrix}
		- D & P_1 - P_0 & P_2 - P_0
		\end{bmatrix}
		\begin{bmatrix}
		t \\[4pt]
		b_1 \\[4pt]
		b_2
		\end{bmatrix}
		=
		O - P_0
		\]
		</p>

		<p>
		For a system \(M x = b\), Cramer’s rule gives:
		</p>

		<p>
		\[
		x =
		\frac{1}{|M|}
		\begin{bmatrix}
		|M_1| \\[4pt]
		|M_2| \\[4pt]
		|M_3|
		\end{bmatrix}
		\]
		</p>

		<p>
		where \(M_i\) is matrix \(M\) with its \(i\)-th column replaced by \(b\).
		</p>

		<p>
		Define the helper vectors:
		</p>

		<p>
		\[
		\begin{aligned}
		S &= O - P_0 \\[4pt]
		S_1 &= D \times E_2 \\[4pt]
		S_2 &= S \times E_1
		\end{aligned}
		\]
		</p>

		<p>
		The determinant of \(M\) is:
		\[
		|M| = S_1 \cdot E_1
		\]
		</p>

		<p>
		Substitute into Cramer’s rule to directly solve for \(t, b_1, b_2\):
		</p>

		<p>
		\[
		\begin{bmatrix}
		t \\[4pt]
		b_1 \\[4pt]
		b_2
		\end{bmatrix}
		=
		\frac{1}{S_1 \cdot E_1}
		\begin{bmatrix}
		S_2 \cdot E_2 \\[4pt]
		S_1 \cdot S \\[4pt]
		S_2 \cdot D
		\end{bmatrix}
		\]
		</p>


		<p>
		A valid intersection occurs if:
		</p>

		<p>
		\[
		\begin{aligned}
		& b_1 \ge 0, \\
		& b_2 \ge 0, \\
		& b_1 + b_2 \le 1, \\
		& t \ge 0
		\end{aligned}
		\]
		</p>

		<p>
		This code is simply an implemention of the process.
		</p>

		<pre><code>
			Vector3D E1 = p2 - p1;
			Vector3D E2 = p3 - p1;
			Vector3D S = r.o - p1;
			Vector3D S1 = cross(r.d, E2);
			Vector3D S2 = cross(S, E1);

			Vector3D sols(dot(S2, E2), dot(S1, S), dot(S2, r.d));
			sols = (1.0 / dot(S1, E1)) * sols;

			double t = sols[0];
			double b1 = sols[1];
			double b2 = sols[2];

			// t within range and barycentric coordinates valid
			if (t > r.min_t && t < r.max_t && b1 >= 0 && b2 >= 0 && (b1 + b2) <= 1) {
			r.max_t = t;
			isect->t = t;
			isect->bsdf = get_bsdf();
			isect->primitive = this;
			isect->n = ((1 - b1 - b2) * n1 + b1 * n2 + b2 * n3).unit();
			return true;
			}
			return false;
			}
		</code></pre>

		<p>
		Finally I implemented the ray-sphere intersection: <code>Sphere::has_intersection(...)</code> and <code>Sphere::intersect(...)</code>.  
		For any point \( \mathbf{p} \) on a sphere's surface, the following equation is satisfied:
		</p>

		<p style="text-align: center;">
		\( (\mathbf{p} - \mathbf{c})^2 - R^2 = 0 \)
		</p>

		<p>
		where \( \mathbf{c} \) is the center of the sphere and \( R \) is its radius.  
		Substituting the ray equation \( \mathbf{r}(t) = \mathbf{o} + t \mathbf{d} \) for \( \mathbf{p} \), we get:
		</p>

		<p style="text-align: center;">
		\( (\mathbf{o} + t\mathbf{d} - \mathbf{c})^2 - R^2 = 0 \)
		</p>

		<p>
		Expanding and simplifying gives a quadratic in \( t \):
		</p>

		<p style="text-align: center;">
		\( at^2 + bt + c = 0 \)
		</p>

		<p>
		with coefficients:
		</p>

		<ul>
		<li>\( a = \mathbf{d} \cdot \mathbf{d} \)</li>
		<li>\( b = 2(\mathbf{o} - \mathbf{c}) \cdot \mathbf{d} \)</li>
		<li>\( c = (\mathbf{o} - \mathbf{c}) \cdot (\mathbf{o} - \mathbf{c}) - R^2 \)</li>
		</ul>

		<p>
		Finally, solve for \( t \) using the quadratic formula.
		</p>


		<div style="display: flex; gap: 20px; justify-content: center; align-items: flex-start;">
		<div style="text-align: center;">

		<img src="part1-banana.png" alt="Description 1" style="max-width: 100%; height: auto; width: 400px;">
		<p><strong>Figure 1:</strong> banana.dae</p>
		</div>
		<div style="text-align: center;">
		<img src="part1-CBempty-before-task-3.png" alt="Description 2" style="max-width: 100%; height: auto; width: 400px;">
		<p><strong>Figure 2:</strong> CBempty.dae</p>
		</div>
		</div>

		
		<h2>Part 2: Bounding Volume Hierarchy</h2>

		<p>In Task 2.1, I constructed a Bounding Volume Hierarchy (BVH). The BVH is an object partition that divides objects into sets in a binary tree structure. The purpose of the BVH is to reduce the number of object-ray tests, thereby making rendering faster.</p>

		<p>The structure of the BVH is as follows:
			<ul>
				<li>A leaf node of the tree consists of objects with the number no more than <code>max_leaf_size</code>.</li>
				<li>During tree construction, in an internal node, the set of objects is divided into two subsets using a appropriate heuristic, and for each subset a BVH tree is constructed recursively, then they are connected to the original internal node as children.</li>
			</ul>
		</p>

		<p>The heuristic I chose for the split is: get the centroid of the entire bounding box, then divide it into two subsets, "left" and "right", based on the centroid of the bounding box of each object, comparing according to coordinates of an axis. The dividing process is performed for each of the three axes, \(x\)-, \(y\)-, and \(z\)-axis, and the most evenly divided result according to one of the axes is adopted. Meanwhile, I handled one exceptional situation: if all objects end up in one subset, then send any one object to the other subset.</p>

		<p>In Task 2.2, I implmented the ray - bounding box intersection test. The test consists of the following steps: For each of the three axes of the bounding box, the time it takes for a ray to pass through the start and end points of the bounding box on that axis is calculated as an interval, and then the intersection of the intervals is calculated.</p>

		<p>For the \(x\)-axis, let \(p_{x0}\) the minimum \(x\)-coordinate of the bounding box, and \(p_{x1}\) the maximum. The calculation of the entry time \(t_{x0}\) and the exit time \(t_{x1}\) depends on the sign of \(d_x\):
			<ul>
				<li>If \(d_x &gt; 0\), then \(t_{x0} = (p_{x0} - o_x)/d_x\) and \(t_{x1} = (p_{x1} - o_x)/d_x\).</li>
				<li>If \(d_x &lt; 0\), then \(t_{x0} = (p_{x1} - o_x)/d_x\) and \(t_{x1} = (p_{x0} - o_x)/d_x\).</li>
				<li>If \(d_x = 0\), the ray is parallel to the bounding box, and the condition depends on \(o_x\): if \(o_x \in [p_{x0}, p_{x1}] \), then the ray is always within the bounding box with regard to \(x\)-axis; otherwise, the ray and the bounding box do not meet at all.</li>
			</ul>
		</p>

		<p>The same calculations are performed for the \(y\)-axis and \(z\)-axis, and the intersection of the resulting intervals is calculated as below. For the ray from time \(t_0\) to time \(t_1\), the final intersection interval is \([t_{0}', t_{1}']\) where</p>
		\[
		t_{0}' = \max(t_{0}, t_{x0}, t_{y0}, t_{z0}) \\
		t_{1}' = \min(t_{1}, t_{x0}, t_{y0}, t_{z0})
		\]

		<p>If the result is an empty interval, then the ray and the bounding box do not intersect. To check for the empty interval, check if \(t_{0}' &gt; t_{1}'\).</p>

		<p>The code below shows the process of the ray - bounding box intersection test:</p>

		<pre><code>
double t0_true = t0, t1_true = t1;
for (int i = 0; i < 3; i++) {
  if (r.d[i] > 0) {
    t0_true = std::max(t0_true, (this->min[i] - r.o[i]) / r.d[i]);
    t1_true = std::min(t1_true, (this->max[i] - r.o[i]) / r.d[i]);
  }
  else if (r.d[i] < 0) {
    t0_true = std::max(t0_true, (this->max[i] - r.o[i]) / r.d[i]);
    t1_true = std::min(t1_true, (this->min[i] - r.o[i]) / r.d[i]);
  }
  else {
    // parallel cases
    if (this->min[i] <= r.o[i] && r.o[i] <= this->max[i]) {
      // the ray passes through the box
    }
    else {
      // does not meet
      return false;
    }
  }
}

if (t0_true > t1_true) {
  return false;
}

t0 = t0_true;
t1 = t1_true;
return true;
		</code></pre>

		<p>In Task 2.3, I implmented the BVH acceleration algorithm for intersection. The following code demonstrates using BVH acceleration to perform an intersection test. The test recursively traverses the BVH tree. If the bounding box of the node and the ray do not intersect, this node can be pruned immediately during the tree traversal. This pruning dramatically reduces the number of object tests.</p>

		<pre><code>
double t0 = ray.min_t;
double t1 = ray.max_t;
if (!node->bb.intersect(ray, t0, t1)) {
	return false;
}

if (node->isLeaf()) {
	bool hit = false;
	for (auto p = node->start; p != node->end; p++) {
		total_isects++;
		if ((*p)->intersect(ray, i)) {
			hit = true;
		}
	}
	return hit;
}

bool hit1 = intersect(ray, i, node->l);
bool hit2 = intersect(ray, i, node->r);
return hit1 || hit2;
		</code></pre>

		<p>Below are some images rendered with normal shading using BVH acceleration.</p>
		
		<figure>
			<img src="maxplanck.png" style="max-width: 100%; height: auto; width: 400px;">
			<div class="caption">dae/meshedit/maxplanck.dae</div>
		</figure>
		<p>Rendering time: 0.1397s</p>
		
		<figure>
			<img src="CBlucy.png" style="max-width: 100%; height: auto; width: 400px;">
			<div class="caption">dae/sky/CBlucy.dae</div>
		</figure>
		<p>Rendering time: 0.0742s</p>

		<figure>
			<img src="cow.png" style="max-width: 100%; height: auto; width: 400px;">
			<div class="caption">dae/meshedit/cow.dae</div>
		</figure>
		<p>Here's a rendering of a scene with 5856 primitives. Without BVH acceleration, it was rendered in 31.2538s with average 1081.159519 intersection tests per ray. With the BVH acceleration, it took 0.0800s and average 2.044837 intersection tests per ray. This demonstrates that BVH acceleration enables faster rendering by dramatically reducing the number of intersection tests.</p>

		<h2>Part 3: Direct Illumination</h2>

		<p>In this part I implemented direct lighting using the one-bounce reflection. The one-bounce reflection traces rays inversely from the camera though surface reflections to the light sources. One-bounce reflections behave differently under uniform hemisphere sampling and importance sampling of lights. Uniform hemisphere sampling samples rays reflected from a surface uniformly in direction over the surface of a unit hemisphere, and the emission at the intersection point of the inverse ray becomes the radiance. On the other hand, importance sampling of lights samples rays from the light sources, and the light for this sample is only casted when there is no obstruction intersecting the ray between the light source and the surface.</p>

		<p>BSDF denotes how much light relative to the incident light is reflected with regard to incident direction and outgoing direction. The diffuse Lambertian BSDF is given as:</p>
		\[
		f_r(p, \omega_i, \omega_o) = \frac{\rho}{\pi}
		\]
		<p>where \(\rho\) is the reflectance (albedo) of the surface.</p>

		<p>We use BSDF \(f_r\) and the radiance of the incident light \(L_i\) to obtain the outgoing light \(L_o\). The rendering equation is:</p>
		\[
		L_o(p, \omega_o) = L_e(p, \omega_o) +
		\int_{\Omega} f_r(p, \omega_i, \omega_o)\, L_i(p, \omega_i)\, \cos\theta_i \, d\omega_i
		\]

		<p>For the integral, use the Monte Carlo estimator to calculate it.</p>
		\[
		\hat{L}_o(p, \omega_o) =
		\frac{1}{N} \sum_{i=1}^N
		\frac{f_r(p, \omega_i, \omega_o)\, L_i(p, \omega_i)\, \cos\theta_i}{p(\omega_i)}
		\]

		<p>For uniform hemisphere sampling, the pdf is \(p(\omega_i) = 1 / (2\pi)\) for all \(\omega_i\) in the surface of hemisphere, while for lighting sampling it is calculated when sampling from light sources.</p>

		<p>The following code shows the implemention for uniform hemisphere sampling.</p>
		<pre><code>
Vector3D L_sum(0, 0, 0);

for (int i = 0; i < num_samples; i++) {
  Vector3D wj = hemisphereSampler->get_sample(); // direction is outward, object coordinates
  double pdf = 1.0 / (2.0 * PI);
  Vector3D fr = isect.bsdf->f(w_out, wj);
  double costheta = cos_theta(wj);

  Vector3D rayDirection = o2w * wj;
  Ray r1(hit_p, rayDirection);
  r1.min_t = EPS_F;
  Intersection isect1;
  bool hit = bvh->intersect(r1, &isect1);
  if (!hit) continue;

  Vector3D Li = isect1.bsdf->get_emission();
  L_sum += (fr * Li * costheta) / pdf;
}

L_out = L_sum * (1.0 / num_samples);

return L_out;
		</code></pre>

		<p>The following code shows the implemention for importance sampling of lights. Noticeable points are:
			<ul>
				<li>For point light sources, it samples only once and instead weights the sample.</li>
				<li>If the ray is intersected between the light source and the surface, the light is blocked and the ray is not casted, leaving the shadow. It checks also whether the ray is unreachable to the surface by checking the sign of <code>costheta</code>.</li>
			</ul>
		</p>
		<pre><code>
Vector3D L_sum(0, 0, 0);
size_t total_sampling_count = scene->lights.size() * ns_area_light;

for (auto light: scene->lights) {
  int sampling_count = light->is_delta_light() ? 1 : ns_area_light;
  int sampling_weight = light->is_delta_light() ? ns_area_light : 1;

  for (int i = 0; i < sampling_count; i++) {
    Vector3D wj_w;  // world-space
    double pdf, distToLight;
    Vector3D radiance = light->sample_L(hit_p, &wj_w, &distToLight, &pdf);

    Vector3D rayDirection = wj_w;

    Vector3D wj_o = w2o * wj_w;
    double costheta = cos_theta(wj_o);
    if (costheta <= 0.0) continue;

    Ray r1(hit_p, rayDirection);
    r1.min_t = EPS_F;
    r1.max_t = distToLight - EPS_F;
    Intersection isect1;
    bool hit = bvh->intersect(r1, &isect1);
    if (hit) {
      continue; // casting the shadow
    }

    Vector3D fr = isect.bsdf->f(w_out, wj_o);
    Vector3D Li = radiance; // * (1.0 / (distToLight * distToLight));
    L_sum += (fr * Li * costheta) / pdf * sampling_weight;
  }
}

L_out = L_sum * (1.0 / total_sampling_count);

return L_out;
		</code></pre>

		<p>The following images show the results of adjusting parameters and choosing between both sampling methods. The adjusted parameters are <code>-s</code> for the number of samples per pixel, and <code>-l</code> for the number of samples per light.</p>

		<div style="display: flex; justify-content: center; gap: 15px;">
		<div style="text-align: center; max-width: 160px;">
			<img src="CBbunny_H_16_8.png" alt="Bunny H_16_8" style="width: 100%;">
			<div class="caption">Uniform Hemisphere Sampling (<code>-s 16 -l 8</code>)</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_1_1.png" alt="Bunny 1_1" style="width: 100%;">
			<div class="caption">Lighting Sampling (<code>-s 1 -l 1</code>)</div>
		</div>
		</div>

		<div style="display: flex; justify-content: center; gap: 15px;">
		<div style="text-align: center; max-width: 160px;">
			<img src="CBbunny_H_64_32.png" alt="Bunny H_64_32" style="width: 100%;">
			<div class="caption">Uniform Hemisphere Sampling (<code>-s 64 -l 32</code>)</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_64_32.png" alt="Bunny 64_32" style="width: 100%;">
			<div class="caption">Lighting Sampling (<code>-s 64 -l 32</code>)</div>
		</div>
		</div>
		
		<p>The following images were generated using the command <code>./pathtracer -t 8 -s 1 -l [lightrays] -m 1 -f bunny_1_[lightrays].png -r 480 360 ../dae/sky/CBbunny.dae</code>, where <code>[lightrays]</code> is the number of light rays. These images demonstrate the effect the number of light rays on rendering has on noise in the soft shadow areas, when using lighting sampling.</p>

		<div style="display: flex; justify-content: center; gap: 15px;">
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_1_1.png" alt="Bunny 1_1" style="width: 100%;">
			<div class="caption">1 light ray</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_1_4.png" alt="Bunny 1_4" style="width: 100%;">
			<div class="caption">4 light rays</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_1_16.png" alt="Bunny 1_16" style="width: 100%;">
			<div class="caption">16 light rays</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="bunny_1_64.png" alt="Bunny 1_64" style="width: 100%;">
			<div class="caption">64 light rays</div>
		</div>
		</div>

		<p>Comparing the two sampling methods, uniform hemisphere sampling has more noises, while lighting sampling shows decent performance even with a small number of samples.</p>

		<h2>Part 4: Global Illumination</h2>
		In this part we are tasked with implementing indirect lighting via Russian Roulette.
		As previously seen in part 3, direct lighting refers to light that travels from a light source to the surface directly without bouncing off any other surface.
		This was computed via the one_bounce_radiance() function.
		Indirect lighting is lighting that arrives at a point after bouncing one or more times off surfaces after originating from a light.
		
		<table border="1" cellpadding="8" cellspacing="0">
		<thead>
			<tr>
			<th>Type</th>
			<th>Bounce Count</th>
			<th>Source</th>
			<th>Visibility Required</th>
			</tr>
		</thead>
		<tbody>
			<tr>
			<td>Emission</td>
			<td>0</td>
			<td>Hit light directly</td>
			<td>Yes</td>
			</tr>
			<tr>
			<td>Direct lighting</td>
			<td>1</td>
			<td>From light</td>
			<td>Yes (not occluded)</td>
			</tr>
			<tr>
			<td>Indirect lighting</td>
			<td>≥2</td>
			<td>From scene</td>
			<td>Indirectly via paths</td>
			</tr>
		</tbody>

		</table>
		The function at_least_one_bounce_radiance(const Ray& r, const Intersection& isect) implements  recursive light integration for indirect lighting, augmenting it with direct lighting and Russian roulette for termination.
		The following steps are implemented:
		
		<ul>
		<li>Construct a local coordinate frame at the intersection point using the surface normal</li>
		<li>Compute the outgoing direction \( w_{\text{out}} \) in local coordinates</li>
		<li>If <code>isAccumBounces</code> is true, always add direct lighting via <code>one_bounce_radiance()</code>; otherwise, add it only at the final bounce</li>
		<li>Check for base case: if <code>r.depth &le; 0</code>, terminate recursion and return <code>L_out</code></li>
		<li>Apply Russian roulette: terminate the path with probability \( 1 - p \), where <code>p = 0.65</code></li>
		<li>Sample a random incoming direction \( w_{\text{in}} \) and BSDF value \( f_r \) using <code>sample_f()</code>; get PDF of the sample</li>
		<li>Transform \( w_{\text{in}} \) to world space and spawn a new ray in that direction</li>
		<li>Intersect the new ray with the scene geometry</li>
		<li>If an intersection occurs:
			<ul>
			<li>Recursively compute indirect lighting at the new intersection point</li>
			<li>Weight the incoming light using the Monte Carlo estimator:<br>
				<code>fr * cos(θ) * L_indirect / (pdf * continuation)</code></li>
			<li>Accumulate the weighted result into <code>L_out</code></li>
			</ul>
		</li>
		<li>Return the total radiance <code>L_out</code></li>
		</ul>

		Depending on whether or not isAccumBounces is true, we either integrate light at every bounce or only at max_ray_depth.
		<pre><code>
		if (isAccumBounces)
			L_out += one_bounce_radiance(r, isect);
		else
		{
			if (max_ray_depth - r.depth + 1 == max_ray_depth)
				L_out += one_bounce_radiance(r, isect);
		}
		</code></pre>

		Next the sampling function sample_f() is used to implement importance sampling utilizing the BSDF at intersection point p.
		w_out is the outgoing direction of light traveling from point p to the camera, or in recursive calls traveling from p' to p.
		w_in is a sampled incoming light direction used to ray trace to the next bounce computed.
		pdf is the probability density function value for the sampled direction w_in, p(w_in).
		<pre><code>
		Vector3D w_in;
		double pdf;
		Vector3D bsdf_sample = isect.bsdf->sample_f(w_out, &w_in, &pdf);
		if (pdf == 0.0) return L_out;
		</code></pre>

		Next we can recursively compute the lighting equation.
		<p>
		<b>Indirect Lighting Estimator:</b><br>
		\[
			L_{\text{indirect}} = \frac{f_r \cdot \cos\theta \cdot L_{\text{child}}}{p \cdot q}
		\]
		</p>
		<pre><code>
		Intersection new_isect;
		if (bvh->intersect(new_ray, &new_isect))
		{
			Vector3D indirect_L = at_least_one_bounce_radiance(new_ray, new_isect);
			double cos_theta = w_in.z;
			if (cos_theta > 0 && pdf > 0)
				L_out += bsdf_sample * cos_theta * indirect_L / (pdf * continuation);
		}
		</code></pre>

		Russian Roulette  is a probabilistic ray termination method. Instead of letting all rays recursive until max depth,
		we instead decide whether to terminate the ray at each step based on a continuation probability.
		We must also divide L_out by the continuation probabiliy as indicated above to preserve unbiased behavior (as indicated above)
		<p>
		If you randomly decide to:
		</p>
		<ul>
		<li><strong>Terminate</strong> with probability \( 1 - p \): return 0</li>
		<li><strong>Continue</strong> with probability \( p \): return \( \frac{f(x)}{p} \)</li>
		</ul>
		<p>
		Then the expected value is:
		</p>
		<p>
		\[
		\mathbb{E}[X] = (1 - p) \cdot 0 + p \cdot \left( \frac{f(x)}{p} \right) = f(x)
		\]
		</p>

		<pre><code>
		// Stop recursion if we've reached depth 0
		if (r.depth <= 0) return L_out;

		// Russian Roulette termination (apply to all bounces, or after a minimum depth)
		const double continuation = 0.65;
		if (!coin_flip(continuation)) return L_out;
		</code></pre>

		<h3>Direct vs Indirect Illumination</h3>
		<div style="display: flex; justify-content: center; gap: 20px;">
		<div style="text-align: center; max-width: 300px;">
			<img src="4 direct only.png" alt="Direct Illumination" style="width: 100%;">
			<div class="caption">Direct Illumination Only</div>
		</div>
		<div style="text-align: center; max-width: 300px;">
			<img src="4 indirect only.png" alt="Indirect Illumination" style="width: 100%;">
			<div class="caption">Indirect Illumination Only</div>
		</div>
		<div style="text-align: center; max-width: 300px;">
			<img src="4 global illum bunny.png" alt="Global Illumination" style="width: 100%;">
			<div class="caption">Global Illumination</div>
		</div>
		</div>

		<h3>Unaccumulated Bounces (isAccumBounces = false)</h3>
		<div style="display: flex; justify-content: center; gap: 15px;">
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce0.png" alt="Bounce 0" style="width: 100%;">
			<div class="caption">Bounce 0</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce1.png" alt="Bounce 1" style="width: 100%;">
			<div class="caption">Bounce 1</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce2.png" alt="Bounce 2" style="width: 100%;">
			<div class="caption">Bounce 2</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce3.png" alt="Bounce 3" style="width: 100%;">
			<div class="caption">Bounce 3</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce4.png" alt="Bounce 4" style="width: 100%;">
			<div class="caption">Bounce 4</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce5.png" alt="Bounce 5" style="width: 100%;">
			<div class="caption">Bounce 5</div>
		</div>
		</div>

		<h3>Accumulated Bounces (isAccumBounces = true)</h3>
		<div style="display: flex; justify-content: center; gap: 15px;">
		<div style="text-align: center; max-width: 160px;">
			<img src="unaccum_bounce0.png" alt="Accumulated 0" style="width: 100%;">
			<div class="caption">Depth 0</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce0.png" alt="Accumulated 1" style="width: 100%;">
			<div class="caption">Depth 1</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce1.png" alt="Accumulated 2" style="width: 100%;">
			<div class="caption">Depth 2</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce2.png" alt="Accumulated 3" style="width: 100%;">
			<div class="caption">Depth 3</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce3.png" alt="Accumulated 4" style="width: 100%;">
			<div class="caption">Depth 4</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce4.png" alt="Accumulated 5" style="width: 100%;">
			<div class="caption">Depth 5</div>
		</div>
		</div>

		<h3>Russian Roulette Rendering</h3>
		<div style="display: flex; justify-content: center; gap: 15px; flex-wrap: wrap;">
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce0.png" alt="RR Depth 0" style="width: 100%;">
			<div class="caption">Depth 0</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce1.png" alt="RR Depth 1" style="width: 100%;">
			<div class="caption">Depth 1</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce2.png" alt="RR Depth 2" style="width: 100%;">
			<div class="caption">Depth 2</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce3.png" alt="RR Depth 3" style="width: 100%;">
			<div class="caption">Depth 3</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce4.png" alt="RR Depth 4" style="width: 100%;">
			<div class="caption">Depth 4</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="accum_bounce5.png" alt="RR Depth 100" style="width: 100%;">
			<div class="caption">Depth 100</div>
		</div>
		</div>

		<h3>Sampling Rate Comparison</h3>
		<div style="display: flex; justify-content: center; gap: 15px; flex-wrap: wrap;">
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s1.png" alt="1 spp" style="width: 100%;">
			<div class="caption">1 Sample/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s2.png" alt="2 spp" style="width: 100%;">
			<div class="caption">2 Samples/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s4.png" alt="4 spp" style="width: 100%;">
			<div class="caption">4 Samples/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s8.png" alt="8 spp" style="width: 100%;">
			<div class="caption">8 Samples/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s16.png" alt="16 spp" style="width: 100%;">
			<div class="caption">16 Samples/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s64.png" alt="64 spp" style="width: 100%;">
			<div class="caption">64 Samples/Pixel</div>
		</div>
		<div style="text-align: center; max-width: 160px;">
			<img src="CBspheres_s1024.png" alt="1024 spp" style="width: 100%;">
			<div class="caption">1024 Samples/Pixel</div>
		</div>
		</div>

		<h3>2-Bounce Rendering</h3>
		<ul>
		<li>Bright overall due to only one indirect bounce.</li>
		<li>Strong color bleeding from walls (red and blue) onto the bunny and floor.</li>
		<li>Shadows begin softening into gradients.</li>
		</ul>

		<h3>3-Bounce Rendering</h3>
		<ul>
		<li>Overall brightness decreases.</li>
		<li>Color bleeding becomes subtler.</li>
		<li>Indirect fill light appears in corners and shadowed areas.</li>
		<li>Increased noise from fewer surviving paths.</li>
		</ul>

		<h3>Comparison with Rasterization</h3>
		<p>
		Rasterization lacks physical global illumination; indirect effects like color bleeding, soft shadows, and ambient fill must be approximated (e.g., SSAO, light maps).<br>
		Path tracing simulates these accurately through extra bounces.
		</p>

		<h2>Part 5: Adaptive Sampling</h2>
		Some pixels in a scene convergence faster or slower during monte carlo light transport integration. This is governed by the variance of the function being integrated.
		Variance of a sample point is determined by scene complexity. For example a point that lies on the boundry of a shadow will have high variance because
		a variety of rays with different radiance arrive at that point. Compare this to a fully lit area where most rays arriving at that point will have high radiance.

		<h3>Mathematical Reason</h3>
		<p>
		Let \( \hat{I}_n \) be the Monte Carlo estimator with \( n \) samples:
		</p>
		<p>
		\[
		\text{Var}[\hat{I}_n] = \frac{\sigma^2}{n}
		\]
		</p>
		<ul>
		<li><strong>Low</strong> \( \sigma^2 \): few samples needed to reduce error</li>
		<li><strong>High</strong> \( \sigma^2 \): many samples required</li>
		</ul>
		<p>
		Pixels with lower \( \sigma^2 \) (i.e., less noise in sampled radiance) converge faster to the true value.
		</p>

		<p>
		Let \( x_k \) be the illuminance of the \( k \)-th sample. We track:
		</p>

		<ul>
		<li>\( s_1 = \sum_{k=1}^{n} x_k \) &nbsp; (sum of samples)</li>
		<li>\( s_2 = \sum_{k=1}^{n} x_k^2 \) &nbsp; (sum of squares)</li>
		</ul>

		<p>
		From this we compute:
		</p>

		<p><strong>Mean:</strong></p>
		<p>
		\[
		\mu = \frac{s_1}{n}
		\]

		<p><strong>Variance:</strong></p>
		<p>
		\[
		\sigma^2 = \frac{1}{n - 1} \left( s_2 - \frac{s_1^2}{n} \right)
		\]
		</p>

		<p>
		To measure convergence, we define a confidence interval on the sample mean using the sample variance and sample count:
		</p>
		<p>
		\[
		I = 1.96 \cdot \frac{\sigma}{\sqrt{n}}
		\]
		</p>
		<p>
		where:
		</p>
		<ul>
		<li>\( \sigma \): standard deviation of illuminance</li>
		<li>\( n \): number of samples traced so far</li>
		</ul>

		<p>
		With 95% confidence, the true mean illuminance lies within:
		</p>
		<p>
		\[
		\mu \pm I = \left[ \mu - 1.96 \cdot \frac{\sigma}{\sqrt{n}}, \; \mu + 1.96 \cdot \frac{\sigma}{\sqrt{n}} \right]
		\]
		</p>
		<p>
		This means there is a 95% probability that the actual average illuminance falls within this range given the observed variance.
		</p>

		<p>
		To determine convergence, we use the criterion:
		</p>
		<p>
		\[
		I \leq \text{maxTolerance} \cdot \mu
		\]
		</p>
		<p>
		If this holds true, we assume the pixel has sufficiently converged and terminate further sampling. 
		By default, <code>maxTolerance = 0.05</code>.
		</p>

		<p>
		Intuitively, \( I \) is small only when the samples’ variance \( \sigma^2 \) is small, 
		or the number of samples \( n \) is large enough. 
		So, the smaller \( I \) is, the more confidently we can conclude that the pixel has converged.
		</p>

		<pre><code>
		void PathTracer::raytrace_pixel(size_t x, size_t y) {

		int num_samples = ns_aa;
		Vector3D sum(0.0, 0.0, 0.0);

		int n = 0;
		double s1 = 0;
		double s2 = 0;
		
		while (n < num_samples) {
			double x_norm = (x + gridSampler->get_sample().x) / sampleBuffer.w;
			double y_norm = (y + gridSampler->get_sample().y) / sampleBuffer.h;
			Ray ray = camera->generate_ray(x_norm, y_norm);
			ray.depth = max_ray_depth;
			Vector3D radiance = est_radiance_global_illumination(ray);
			sum += radiance;

			n += 1;
			double illuminance = radiance.illum();
			s1 += illuminance;
			s2 += illuminance * illuminance;

			if (n % samplesPerBatch == 0 && n > 1) {
				double mean = s1 / n;
				double variance = (s2 - ((s1 * s1) / n)) / (n - 1);
				double I = 1.96 * sqrt(variance / n);
				if (I <= maxTolerance * mean) {
					break;
				}
			}
		}
		
		sum = sum / n;
		sampleBuffer.update_pixel(sum, x, y);
		sampleCountBuffer[x + y * sampleBuffer.w] = n;
		}
		</code></pre>

		<h3>Adaptive Sampling Comparison</h3>
		<div class="image-row" style="display: flex; justify-content: center; gap: 40px;">
		<div class="image-column" style="text-align: center;">
			<img src="bunny_adaptive_result.png" alt="Scene 1 Rendered Image" style="width: 400px;">
			<div class="caption">Scene 1: Final Render (2048 spp)</div>
		</div>
		<div class="image-column" style="text-align: center;">
			<img src="bunny_adaptive_result_rate.png" alt="Scene 1 Sampling Rate Image" style="width: 400px;">
			<div class="caption">Scene 1: Sampling Rate Visualization</div>
		</div>
		</div>

		<br><br>

		<div class="image-row" style="display: flex; justify-content: center; gap: 40px;">
		<div class="image-column" style="text-align: center;">
			<img src="spheres_adaptive_result.png" alt="Scene 2 Rendered Image" style="width: 400px;">
			<div class="caption">Scene 2: Final Render (2048 spp)</div>
		</div>
		<div class="image-column" style="text-align: center;">
			<img src="spheres_adaptive_result_rate.png" alt="Scene 2 Sampling Rate Image" style="width: 400px;">
			<div class="caption">Scene 2: Sampling Rate Visualization</div>
		</div>
		</div>
	

		</div>
	</body>
</html>